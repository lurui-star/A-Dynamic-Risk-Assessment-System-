{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd3ab6d0-e106-405f-867e-4eac4776f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import timeit\n",
    "import logging\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "323342e7-eb86-4a09-95ea-ae9487dc8438",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aa7840c-bd1f-43fa-86bc-d70ee4ae3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('src/config.json','r') as f:\n",
    "    config = json.load(f) \n",
    "\n",
    "prod_deployment_path = os.path.join(config['prod_deployment_path']) \n",
    "data_path=os.path.join(config['output_folder_path']) \n",
    "test_data_path=os.path.join(config['test_data_path']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "105afa93-1da0-4d54-98ef-4a70b0e9a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predictions(X_df):\n",
    "    logging.info(\"Loading deployed model\")\n",
    "    model = pickle.load(open(os.path.join(prod_deployment_path,'trainedmodel.pkl'), 'rb'))\n",
    "    logging.info(\"Running predictions on data\")\n",
    "    y_pred = model.predict(X_df)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddf64e13-d429-45de-92b6-a6d656f90dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_summary():\n",
    "    logging.info(\"Loading and preparing finaldata.csv\")\n",
    "    data_df = pd.read_csv(os.path.join(data_path, 'finaldata.csv'))\n",
    "    data_df = data_df.drop(['exited'], axis=1)\n",
    "    data_df = data_df.select_dtypes('number')\n",
    "    logging.info(\"Calculating statistics for data\")\n",
    "    statistics_dict = {}\n",
    "    for col in data_df.columns:\n",
    "        mean = data_df[col].mean()\n",
    "        median = data_df[col].median()\n",
    "        std = data_df[col].std()\n",
    "    \n",
    "        statistics_dict[col] = {'mean': mean, 'median': median, 'std': std}\n",
    "    return(statistics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb257912-08f6-4d1b-9ef4-64ee31256508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_percentage():\n",
    "    logging.info(\"Loading and preparing finaldata.csv\")\n",
    "    data_df = pd.read_csv(os.path.join(data_path, 'finaldata.csv'))\n",
    "    logging.info(\"Calculating missing data percentage\")\n",
    "    missing_list = {col: {'percentage': perc} for col, perc in zip(\n",
    "        data_df.columns, data_df.isna().sum() / data_df.shape[0] * 100)}\n",
    "\n",
    "    return( missing_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "864dc441-97c2-424d-8d84-0d950319ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ingestion_timing():\n",
    "    starttime = timeit.default_timer()\n",
    "    _ = subprocess.run(['python', 'ingestion.py'], capture_output=True)\n",
    "    timing = timeit.default_timer() - starttime\n",
    "    return timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9106b620-a644-48db-8363-460e1ef6fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _training_timing():\n",
    "    starttime = timeit.default_timer()\n",
    "    _ = subprocess.run(['python', 'training.py'], capture_output=True)\n",
    "    timing = timeit.default_timer() - starttime\n",
    "    return timing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14f99117-6eb7-48ba-bdcc-3a8a609ff77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execution_time():\n",
    "    logging.info(\"Calculating time for ingestion.py\")\n",
    "    ingestion_time = []\n",
    "    for _ in range(20):\n",
    "        time = _ingestion_timing()\n",
    "        ingestion_time.append(time)\n",
    "\n",
    "    logging.info(\"Calculating time for training.py\")\n",
    "    training_time = []\n",
    "    for _ in range(20):\n",
    "        time = _training_timing()\n",
    "        training_time.append(time)\n",
    "\n",
    "    ret_list = [\n",
    "        {'ingest_time_mean': np.mean(ingestion_time)},\n",
    "        {'train_time_mean': np.mean(training_time)}\n",
    "    ]\n",
    "\n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c577ff01-d4b4-4943-9ef5-0f6cf1876c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outdated_packages_list(request_file='request.txt'):\n",
    "    logging.info(\"Checking outdated dependencies\")\n",
    "    \n",
    "    # Step 1: Run pip list to get outdated packages\n",
    "    result = subprocess.run(\n",
    "        ['pip', 'list', '--outdated'],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "\n",
    "    # Check if the subprocess ran successfully\n",
    "    if result.returncode != 0:\n",
    "        logging.error(f\"Error running pip list: {result.stderr}\")\n",
    "        return []\n",
    "\n",
    "    dep = result.stdout\n",
    "    # Split lines and ignore the first 2 (header lines)\n",
    "    dep_lines = dep.split('\\n')[2:]  # Skip the first two lines of the output header\n",
    "\n",
    "    # Step 2: Parse the pip list output\n",
    "    outdated_deps = []\n",
    "    for line in dep_lines:\n",
    "        if line.strip():  # Skip empty lines\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 3:\n",
    "                # Package name, current version, latest version\n",
    "                outdated_deps.append({\n",
    "                    'package': parts[0],\n",
    "                    'current_version': parts[1],\n",
    "                    'latest_version': parts[2]\n",
    "                })\n",
    "    \n",
    "    # Convert the outdated list to a DataFrame\n",
    "    outdated_deps_df = pd.DataFrame(outdated_deps)\n",
    "    \n",
    "    # Step 3: Read the request.txt file to get the list of packages\n",
    "    try:\n",
    "        with open(request_file, 'r') as f:\n",
    "            requested_packages = [line.strip().split('==')[0] for line in f if line.strip()]\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File {request_file} not found.\")\n",
    "        return outdated_deps_df\n",
    "\n",
    "    # Step 4: Filter outdated packages that are in request.txt\n",
    "    requested_outdated_deps = outdated_deps_df[outdated_deps_df['package'].isin(requested_packages)]\n",
    "    \n",
    "    # Return only the outdated packages that are in request.txt, without extra print/logging\n",
    "    return requested_outdated_deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "733e0d18-a091-4c25-b721-d1387f2785d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Checking outdated dependencies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package</th>\n",
       "      <th>current_version</th>\n",
       "      <th>latest_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anyio</td>\n",
       "      <td>4.6.2</td>\n",
       "      <td>4.8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>debugpy</td>\n",
       "      <td>1.8.11</td>\n",
       "      <td>1.8.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jupyterlab</td>\n",
       "      <td>4.1.3</td>\n",
       "      <td>4.3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mistune</td>\n",
       "      <td>3.0.2</td>\n",
       "      <td>3.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nbconvert</td>\n",
       "      <td>7.16.4</td>\n",
       "      <td>7.16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>notebook</td>\n",
       "      <td>7.1.3</td>\n",
       "      <td>7.3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>numpy</td>\n",
       "      <td>2.0.1</td>\n",
       "      <td>2.2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pydantic</td>\n",
       "      <td>2.10.4</td>\n",
       "      <td>2.10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pygments</td>\n",
       "      <td>2.18.0</td>\n",
       "      <td>2.19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pytest</td>\n",
       "      <td>6.2.5</td>\n",
       "      <td>8.3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pytz</td>\n",
       "      <td>2024.1</td>\n",
       "      <td>2024.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>referencing</td>\n",
       "      <td>0.35.1</td>\n",
       "      <td>0.36.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>scipy</td>\n",
       "      <td>1.15.0</td>\n",
       "      <td>1.15.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>starlette</td>\n",
       "      <td>0.41.3</td>\n",
       "      <td>0.45.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>uvicorn</td>\n",
       "      <td>0.15.0</td>\n",
       "      <td>0.34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ydata-profiling</td>\n",
       "      <td>4.10.0</td>\n",
       "      <td>4.12.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            package current_version latest_version\n",
       "0             anyio           4.6.2          4.8.0\n",
       "2           debugpy          1.8.11         1.8.12\n",
       "3        jupyterlab           4.1.3          4.3.4\n",
       "4           mistune           3.0.2          3.1.0\n",
       "5         nbconvert          7.16.4         7.16.5\n",
       "6          notebook           7.1.3          7.3.2\n",
       "7             numpy           2.0.1          2.2.2\n",
       "9          pydantic          2.10.4         2.10.5\n",
       "10         Pygments          2.18.0         2.19.1\n",
       "13           pytest           6.2.5          8.3.4\n",
       "14             pytz          2024.1         2024.2\n",
       "17      referencing          0.35.1         0.36.1\n",
       "18            scipy          1.15.0         1.15.1\n",
       "21        starlette          0.41.3         0.45.2\n",
       "22          uvicorn          0.15.0         0.34.0\n",
       "24  ydata-profiling          4.10.0         4.12.1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdated_packages_list(request_file='requirements.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18075e37-5d03-4fd8-bb92-2f1368817a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading and preparing testdata.csv\n",
      "INFO:root:Loading deployed model\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/production_deployment/production_deployment/trainedmodel.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtestdata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m X_df \u001b[38;5;241m=\u001b[39m test_df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorporation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexited\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel predictions on testdata.csv:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m----> 8\u001b[0m       \u001b[43mmodel_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_df\u001b[49m\u001b[43m)\u001b[49m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummary statistics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(dataframe_summary(), indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m, in \u001b[0;36mmodel_predictions\u001b[0;34m(X_df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_predictions\u001b[39m(X_df):\n\u001b[1;32m      2\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading deployed model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprod_deployment_path\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproduction_deployment/trainedmodel.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning predictions on data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_df)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/production_deployment/production_deployment/trainedmodel.pkl'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    logging.info(\"Loading and preparing testdata.csv\")\n",
    "    test_df = pd.read_csv(os.path.join(test_data_path, 'testdata.csv'))\n",
    "    X_df = test_df.drop(['corporation', 'exited'], axis=1)\n",
    "\n",
    "    print(\"Model predictions on testdata.csv:\",\n",
    "          model_predictions(X_df), end='\\n\\n')\n",
    "\n",
    "    print(\"Summary statistics\")\n",
    "    print(json.dumps(dataframe_summary(), indent=4), end='\\n\\n')\n",
    "\n",
    "    print(\"Missing percentage\")\n",
    "    print(json.dumps(missing_percentage(), indent=4), end='\\n\\n')\n",
    "\n",
    "    print(\"Execution time\")\n",
    "    print(json.dumps(execution_time(), indent=4), end='\\n\\n')\n",
    "\n",
    "    print(\"Outdated Packages\")\n",
    "    print(outdated_packages_list(request_file='requirements.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dynamic_risk_assess)",
   "language": "python",
   "name": "dynamic_risk_assess"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
